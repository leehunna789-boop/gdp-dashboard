import torch
from transformers import pipeline
import soundfile as sf
from rvc_python import rvc
import os

# --- PART 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ BARK ---
def generate_bark_singing(lyrics, output_bark_path):
    print("üì¢ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å Bark...")
    device = 0 if torch.cuda.is_available() else -1
    # ‡πÉ‡∏ä‡πâ bark-small ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≠‡∏°‡πÅ‡∏£‡∏á‡πÉ‡∏ä‡πâ suno/bark
    synthesizer = pipeline("text-to-speech", model="suno/bark-small", device=device)
    
    # ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏™‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á
    formatted_lyrics = f"[music] ‚ô™ {lyrics} ‚ô™"
    
    generation_params = {
        "do_sample": True,
        "speaker_preset": "v2/en_speaker_6" 
    }
    
    speech = synthesizer(formatted_lyrics, forward_params=generation_params)
    sf.write(output_bark_path, speech["audio"], samplerate=speech["sampling_rate"])
    print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {output_bark_path}")

# --- PART 2: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RVC ---
def apply_rvc(input_wav, model_pth, final_output):
    print("üé≠ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏î‡πâ‡∏ß‡∏¢ RVC...")
    rvc.convert(
        model_path=model_pth,
        f0_method='rmvpe', # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á
        f0_up_key=0,       # ‡∏õ‡∏£‡∏±‡∏ö +12 ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏≤‡∏¢‡πÑ‡∏õ‡∏´‡∏ç‡∏¥‡∏á)
        input_path=input_wav,
        output_path=final_output
    )
    print(f"‚ú® ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: {final_output}")

# --- ‡∏£‡∏±‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ---
if __name__ == "__main__":
    lyrics = "Twinkle, twinkle, little star, how I wonder what you are"
    temp_bark = "temp_bark_voice.wav"
    my_model = "my_model.pth" # <--- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Drive
    final_result = "final_ai_cover.wav"

    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á
    generate_bark_singing(lyrics, temp_bark)

    # 2. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RVC
    if os.path.exists(my_model):
        apply_rvc(temp_bark, my_model, final_result)
    else:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• {my_model} ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
